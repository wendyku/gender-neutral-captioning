{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Neutral Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Preparing Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_activity_list, get_gender_nouns, get_qualified_dataset, get_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ground truth labels in train set\n",
      "\n",
      "Caption 0 processed, out of 414113 captions\n",
      "No. of qualified images processed: 0\n",
      "\n",
      "Caption 100000 processed, out of 414113 captions\n",
      "No. of qualified images processed: 6452\n",
      "\n",
      "Caption 200000 processed, out of 414113 captions\n",
      "No. of qualified images processed: 13359\n",
      "\n",
      "Caption 300000 processed, out of 414113 captions\n",
      "No. of qualified images processed: 24080\n",
      "\n",
      "Caption 400000 processed, out of 414113 captions\n",
      "No. of qualified images processed: 34712\n",
      "\n",
      "Evaluating ground truth labels in val set\n",
      "\n",
      "Caption 0 processed, out of 202654 captions\n",
      "No. of qualified images processed: 35500\n",
      "\n",
      "Caption 100000 processed, out of 202654 captions\n",
      "No. of qualified images processed: 42016\n",
      "\n",
      "Caption 200000 processed, out of 202654 captions\n",
      "No. of qualified images processed: 52292\n"
     ]
    }
   ],
   "source": [
    "annotations_path = './data/annotations/'\n",
    "activity_image_ids = get_activity_list()\n",
    "gender_nouns_lookup = get_gender_nouns()\n",
    "captions_dict, im_gender_summary = get_qualified_dataset(annotations_path, gender_nouns_lookup, save_file = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Select Training Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our motivation of the project is to counter the bias in the dataset. As ground truth labels are not availabie from the original COCO dataset, we are experimenting with different methods of balancing the dataset. In the **get_training_data** function in data_utils.py, there are 8 different modes of generating data.\n",
    "\n",
    "    - random: randomized selection of qualified images\n",
    "    - balanced_mode: balanced ratio between male, female and neutral\n",
    "    - balanced_clean: balanced ratio between male, female and neutral, only use images when all captions agree on using the same gender\n",
    "    - balanced_gender_only: same as balanced_mode, but without neutral captions\n",
    "    - balanced_clean_noun: balanced ratio between male, female and neutral, only use images when all captions agree on using the same noun\n",
    "    - clean_noun: only use images when all captions agree on the same noun\n",
    "    - activity_balanced: from activity tagged image sets, choose same ratio of male, female, neutral image\n",
    "    - activity_balanced_clean: similar to activity_balanced, but all captions must agree on the same gender\n",
    "    \n",
    "Note that it is possible that output size may be smaller than training_size, especially for activity_balanced and activity_balanced_clean. As for certain activities, the sample size of clean data might be limited for some classes, e.g. women wearing tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captions of 1000 images are added\n"
     ]
    }
   ],
   "source": [
    "random = get_training_data(im_gender_summary, captions_dict, activity_image_ids, training_size = training_size, mode = \"balanced_clean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Train Model/ Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV. Predict on selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
