{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Using cached bert_score-0.3.2-py3-none-any.whl (52 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (4.42.1)\n",
      "Collecting transformers>=2.2.0\n",
      "  Using cached transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (1.5.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (1.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (3.1.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from bert_score) (2.22.0)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.12.45-py2.py3-none-any.whl (128 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.85-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Processing /Users/kuly/Library/Caches/pip/wheels/81/94/a4/1cd28c369532c89aaa9b39580100990d74553e550b1942a7dc/sacremoses-0.0.41-py3-none-any.whl\n",
      "Collecting tokenizers==0.5.2\n",
      "  Using cached tokenizers-0.5.2.tar.gz (64 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hProcessing /Users/kuly/Library/Caches/pip/wheels/52/98/5c/8d5d7a5321d2de463dfc6f7b32aab8b16e564cfce553b28daf/regex-2020.4.4-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from transformers>=2.2.0->bert_score) (3.0.12)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->bert_score) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.1->bert_score) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.1->bert_score) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->bert_score) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->bert_score) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->bert_score) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->bert_score) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->bert_score) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->bert_score) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->bert_score) (1.25.8)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Using cached s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.16.0,>=1.15.45\n",
      "  Using cached botocore-1.15.45-py2.py3-none-any.whl (6.1 MB)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers>=2.2.0->bert_score) (0.14.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers>=2.2.0->bert_score) (1.14.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers>=2.2.0->bert_score) (7.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->bert_score) (46.0.0.post20200309)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/anaconda3/bin/python /opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /var/folders/jw/5s20_fc54fqfzynqdlgsx4zr0000gn/T/tmpskcmh9je\n",
      "       cwd: /private/var/folders/jw/5s20_fc54fqfzynqdlgsx4zr0000gn/T/pip-install-jqxhnxwz/tokenizers\n",
      "  Complete output (36 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/tokenizers\n",
      "  copying tokenizers/__init__.py -> build/lib/tokenizers\n",
      "  creating build/lib/tokenizers/models\n",
      "  copying tokenizers/models/__init__.py -> build/lib/tokenizers/models\n",
      "  creating build/lib/tokenizers/decoders\n",
      "  copying tokenizers/decoders/__init__.py -> build/lib/tokenizers/decoders\n",
      "  creating build/lib/tokenizers/normalizers\n",
      "  copying tokenizers/normalizers/__init__.py -> build/lib/tokenizers/normalizers\n",
      "  creating build/lib/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.py -> build/lib/tokenizers/pre_tokenizers\n",
      "  creating build/lib/tokenizers/processors\n",
      "  copying tokenizers/processors/__init__.py -> build/lib/tokenizers/processors\n",
      "  creating build/lib/tokenizers/trainers\n",
      "  copying tokenizers/trainers/__init__.py -> build/lib/tokenizers/trainers\n",
      "  creating build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/byte_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/base_tokenizer.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/__init__.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/char_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/bert_wordpiece.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/__init__.pyi -> build/lib/tokenizers\n",
      "  copying tokenizers/models/__init__.pyi -> build/lib/tokenizers/models\n",
      "  copying tokenizers/decoders/__init__.pyi -> build/lib/tokenizers/decoders\n",
      "  copying tokenizers/normalizers/__init__.pyi -> build/lib/tokenizers/normalizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/processors/__init__.pyi -> build/lib/tokenizers/processors\n",
      "  copying tokenizers/trainers/__init__.pyi -> build/lib/tokenizers/trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: Can not find Rust compiler\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25hFailed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b4e8c507db9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install bert_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bert_score'"
     ]
    }
   ],
   "source": [
    "!pip install bert_score\n",
    "import bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cbabed4f5779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_image_ids_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bert_score'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "from model_utils import predict_for_test_samples\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from bert_score import score\n",
    "\n",
    "def test(vocab_path, model_path, training_image_ids_path):\n",
    "    sample_size = 100\n",
    "    test_pred_captions = predict_for_test_samples(image_folder_path = image_folder_path,\\\n",
    "                         sample_size = sample_size, vocab_path = vocab_path, model_path = model_path,\\\n",
    "                           training_image_ids_path = training_image_ids_path)\n",
    "\n",
    "    #load obj\n",
    "    im_gender_summary = load_obj(\"im_gender_summary\")\n",
    "    captions_dict = load_obj(\"captions_dict\")\n",
    "\n",
    "    gt = []\n",
    "    pred_gender = []\n",
    "    bleus = []\n",
    "    for image_id, caption in test_pred_captions.items():\n",
    "        gt.append(im_gender_summary[image_id]['pred_gt'])\n",
    "        pred_gender.append(caption_to_gender(caption))\n",
    "        ref_captions = captions_dict[image_id]\n",
    "        ref_captions = [c.split() for c in ref_captions]\n",
    "        bleus.append(bleu.sentence_bleu(ref_captions, caption.split()))\n",
    "\n",
    "    _, _, F1 = score(ref_captions, caption.split(), bert=\"bert-base-uncased\")\n",
    "\n",
    "    return confusion_matrix(gt, pred_gender), accuracy_score(gt, pred_gender), bleus.mean(), F1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "results = dict()\n",
    "\n",
    "model_dirs = glob.glob('./testmodels/*/')\n",
    "for d in model_dirs:\n",
    "    # get name\n",
    "    p = re.compile(r'(?<=testmodels/)(.*)(?=/)')\n",
    "    name = p.findall(d)[0]\n",
    "    \n",
    "    # get paths\n",
    "    vocab_path = d + 'vocab.pkl'\n",
    "    model_path = d +'best-model.pkl'\n",
    "    training_image_ids_path = d +'training_image_ids.pkl'\n",
    "    \n",
    "    conf_matrix, accuracy, bleu, bert = test(vocab_path, model_path, training_images_ids_path)\n",
    "    \n",
    "    results[name] = dict()\n",
    "    results[name]['confusion_matrix'] = conf_matrix\n",
    "    results[name]['accuracy'] = accuracy\n",
    "    results[name]['bleu'] = bleu\n",
    "    results[name]['bert_f1'] = bert\n",
    "    print(f\"Evaluated {name}: {results[name]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
