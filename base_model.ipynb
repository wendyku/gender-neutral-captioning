{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "image_path = './data/images/'\n",
    "annotations_path = './data/annotations'\n",
    "images_path = glob.glob(f\"{image_path}/train2014/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use COCO's instances json file to identify images with humans\n",
    "with open(f'{annotations_path}/instances_train2014.json') as f:\n",
    "  instances_json = json.load(f)\n",
    "image_category_dict = dict()\n",
    "for i in range(len(instances_json['annotations'])):\n",
    "    cat_id = instances_json['annotations'][i]['category_id']\n",
    "    image_id = instances_json['annotations'][i]['image_id']\n",
    "    if cat_id in image_category_dict:\n",
    "        image_category_dict[cat_id] += [image_id]\n",
    "    else:\n",
    "        image_category_dict[cat_id] = [image_id]\n",
    "        \n",
    "human_image_ids = set(image_category_dict[1]) #human images are of category 1, remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionaries to map image ids to filenames and captions to images\n",
    "with open(f'{annotations_path}/captions_train2014.json') as f:\n",
    "  captions_json = json.load(f)\n",
    "\n",
    "image_id_dict = dict()\n",
    "# key = image_id, value = image_fname\n",
    "for i in range(len(captions_json['images'])):\n",
    "    image_id = captions_json['images'][i]['id']\n",
    "    image_fname = captions_json['images'][i]['file_name']\n",
    "    image_id_dict[image_id] = image_fname\n",
    "\n",
    "captions_dict = dict()\n",
    "# key = image_id, value = list of captions\n",
    "for i in range(len(captions_json['annotations'])):\n",
    "    image_id = captions_json['annotations'][i]['image_id']\n",
    "    caption = captions_json['annotations'][i]['caption']\n",
    "    if image_id in captions_dict:\n",
    "        captions_dict[image_id] += [caption]\n",
    "    else:\n",
    "        captions_dict[image_id] = [caption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample out of all human images\n",
    "N = 100\n",
    "training_image_ids = random.sample(human_image_ids, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
