{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bias_analysis import *\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# top 12 biased verbs from both genders\n",
    "bias_activities = ('driving','passing','catching','reading','touching','pulling','wedding','jumping','skateboarding','pulled','riding',\n",
    "                   'pushing','cutting','having','laying','cut','petting','waiting','talking','haired','overlooking','staring','typing')\n",
    "\n",
    "# top 12 biased nouns from both genders\n",
    "bias_items = ('tennis','dirt','skateboard','grass','carriage','beer','kite','beach','road','wagon','bags','surfboard',\n",
    "              'dress','lap','bed','flowers','mouth','bridle','fire','teeth','curb','device','leash','face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('female_word_file.txt') as f:\n",
    "    female_nouns = [line[:-1] for line in f]\n",
    "with open('male_word_file.txt') as f:\n",
    "    male_nouns = [line[:-1] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 25 samples of each gender doing activity (ie. total 50 samples)\n",
    "def get_activity_ids(ids, gender, bias_items, n_samples):\n",
    "    gender_nouns = male_nouns if gender=='man' else female_nouns\n",
    "    activity_ids_dict = defaultdict(list)\n",
    "    captions_dict = defaultdict(list)\n",
    "    print(\"Getting samples: \",n_samples, \"nos.\")\n",
    "       \n",
    "    with open('captions_train2014.json') as file:\n",
    "        coco_data = json.load(file)\n",
    "\n",
    "    for item in coco_data['annotations']:\n",
    "        bias_items = [i for i in bias_items if len(activity_ids_dict[i])<n_samples]\n",
    "        \n",
    "        # if all n_samples collected for all bias_items, break\n",
    "        if bias_items==[]:\n",
    "            break\n",
    "\n",
    "        # going through each annotation\n",
    "        if item['image_id'] in ids:\n",
    "            for activity in bias_items:\n",
    "                if any(word in gender_nouns for word in item['caption'].split()) and (activity in item['caption'].split()):\n",
    "                    if item['image_id'] not in activity_ids_dict[activity]:      \n",
    "                        activity_ids_dict[activity].append(item['image_id'])  \n",
    "                        captions_dict[activity].append(item['caption'])  \n",
    "\n",
    "    return activity_ids_dict,captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allids():\n",
    "    with open('instances_train2014.json') as file:\n",
    "        data = json.load(file)\n",
    "    all_ids = []\n",
    "    for item in data['annotations']:\n",
    "        if item['category_id'] == 1:\n",
    "            all_ids.append(item['image_id'])\n",
    "    print(\"Got All IDS\")\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples = 25\n",
    "all_ids = get_allids()\n",
    "for bias_list in [bias_items,bias_activities]:\n",
    "    \n",
    "    for gender in ['man','woman']:\n",
    "        ids, captions = get_activity_ids(all_ids,gender,bias_list,n_samples)\n",
    "        for activity in ids:\n",
    "            print(activity, len(ids[activity]))\n",
    "            with open(activity+\".txt\",'a') as out:\n",
    "                if bias_list == bias_activities: out.write(\"\\n\")\n",
    "                write_ids = [str(i) for i in ids[activity]]\n",
    "                out.write(\"\\n\".join(write_ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting images and copying to folder\n",
    "filenames = []\n",
    "with open('captions_val2014.json') as file:\n",
    "    coco_data = json.load(file)\n",
    "for item in coco_data['images']:\n",
    "    if item['id'] in ids['tennis']:\n",
    "        filenames.append(item['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder='trainfolder'\n",
    "for image in filenames:\n",
    "    image = \"val2014/\" + image \n",
    "    shutil.copy(image, target_folder)\n",
    "print(\"Copied sampled images to {}\".format(target_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_list_paths = glob.glob(\"*.txt\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('activity_nouns')\n",
    "os.mkdir('activity_verbs')\n",
    "for file in activity_list_paths:\n",
    "    with open(file) as f:\n",
    "        length = sum([1 for line in f])\n",
    "    if (length==50) and file[:-4] in bias_activities: \n",
    "        try:\n",
    "            shutil.move(file, 'activity_verbs')\n",
    "        except:print()\n",
    "    if (length==50) and file[:-4] in bias_items: \n",
    "        try:\n",
    "            shutil.move(file, 'activity_nouns')\n",
    "        except:print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_list_paths = glob.glob(\"activity_verbs/*.txt\")  \n",
    "\n",
    "files = [item.split('\\\\')[1] for item in activity_list_paths]\n",
    "for file,name in zip(activity_list_paths,files):\n",
    "    new_name = \"intersection_\"+name[:-4]+\"_person.txt\"\n",
    "    os.rename(file,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_list_paths = glob.glob(\"activity_verbs/*.txt\")  \n",
    "files = [item.split('\\\\')[1] for item in activity_list_paths]\n",
    "final_verbs = [file[:-4].split('_')[1] for file in files]\n",
    "\n",
    "activity_list_paths = glob.glob(\"activity_nouns/*.txt\")  \n",
    "files = [item.split('\\\\')[1] for item in activity_list_paths]\n",
    "final_nouns = [file[:-4].split('_')[1] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cutting', 'cut', 'having', 'jumping', 'laying', 'petting', 'pulling', 'reading', 'riding', 'staring', 'talking', 'touching', 'waiting', 'wedding'] ['dirt', 'dress', 'face', 'fire', 'grass', 'kite', 'lap', 'road', 'skateboard', 'surfboard', 'teeth', 'tennis']\n"
     ]
    }
   ],
   "source": [
    "print(final_verbs,final_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7650",
   "language": "python",
   "name": "7650"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
